---
title: "Extracting data for n-back"
params: 
  ExperimentID: [15096,16303]
  rootdir: /home/user/Desktop/Documents/TimeSocialDistancing
output:
  html_document: 
    df_print: paged
    toc: yes
  html_notebook:
    code_folding: hide
    toc: yes
---

```{r setup, include= FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
```

```{r, include= F}
library(tidyverse)
source('helpers.R')
library(rmarkdown)
library(stringr)
```

#Read and Describe Data
```{r}
OrigNback <- gimmedata(DataDir = file.path(params$rootdir,'data'),UniqueName = '.back',Session = '1', ExperimentID = 15096)

Nback <- OrigNback %>%
  filter(str_detect(display, "block1back") | str_detect(display, "block3back")) %>%
  select(Session, PID, Run, UniqueName, ILI, duration, randomise_blocks,`Zone Type`, duration, Response, `Reaction Time`, Correct, Attempt, `UTC Timestamp`, `Spreadsheet Name`) %>%
  rename(nback = UniqueName,
        Zone.Type = `Zone Type`,
        randomblock = randomise_blocks,
         UTC.Timestamp = `UTC Timestamp`,
         Spreadsheet = `Spreadsheet Name`,
         Reaction.Time = `Reaction Time`)  %>%
  mutate(UTC.Timestamp = as.numeric((as.character(UTC.Timestamp))),
         ILI = as.factor(ifelse(ILI  == 1500, "1500ms", "1800ms")),
         duration = as.factor(duration),
         condition = ifelse(duration == "45s"  & ILI == "1500ms", 1, 0),
         condition = ifelse(duration == "90s" & ILI == "1500ms", 2, condition),
         condition = ifelse(duration == "45s"  & ILI == "1800ms", 3, condition),
         condition = ifelse(duration == "90s"  & ILI == "1800ms", 4, condition))
```

```{r}
#list of participants to remove --> some participants logged twice or 3 x with a different login
#removing which participants ID that we don't want
participants_to_rm = c("1377295", "1373766", "1347792", "1358571","1348787","1318460",  "1347194", "1366463", "1330740", "1314652")
Nback<- Nback %>%
  filter(!(PID %in% participants_to_rm))


Nback %>%
  count(PID)   #417 --> 412 participants

```


#Read spreadsheets used for each trials and add variable that indicates the number of target letters
```{r}

sprdsheet1b1 <-read.csv("/home/user/Desktop/Documents/TimeSocialDistancing/data/spreadsheet1back_1.csv") %>%
  mutate(Spreadsheet = "n_back1")
sprdsheet1b2 <-read.csv("/home/user/Desktop/Documents/TimeSocialDistancing/data/spreadsheet1back_2.csv")%>%
  mutate(Spreadsheet = "n_back2")
sprdsheet3b1 <-read.csv("/home/user/Desktop/Documents/TimeSocialDistancing/data/spreadsheet3back_1.csv")%>%
  mutate(Spreadsheet = "n_back1")
sprdsheet3b2 <-read.csv("/home/user/Desktop/Documents/TimeSocialDistancing/data/spreadsheet3back_2.csv")%>%
  mutate(Spreadsheet = "n_back2")


sprdsheet <- bind_rows(sprdsheet1b1, sprdsheet1b2, sprdsheet3b1, sprdsheet3b2) %>%
   mutate(condition = ifelse(duration == "45s"  & ILI == 1500, 1, 0),
         condition = ifelse(duration == "90s" & ILI == 1500, 2, condition),
         condition = ifelse(duration == "45s"  & ILI == 1800, 3, condition),
         condition = ifelse(duration == "90s"  & ILI == 1800, 4, condition)) %>%
   filter(display == "block1back" | display == "block3back") %>%
        mutate(nback = ifelse(display == "block1back", "1back", "3back")) 
 

nb_target <- sprdsheet %>%
  filter(condition !=0) %>%
  group_by(nback, Spreadsheet, condition) %>%
  summarise(ntarget = sum(ANSWER == "Left"), notarget = sum(ANSWER == "Down"))
nb_target

Nback <- left_join(Nback, nb_target, by = c("nback", "Spreadsheet", "condition")) %>%
  select(-Spreadsheet)
```


```{r}
ConfTrack <- gimmedata(DataDir = file.path(params$rootdir,'data'),UniqueName = 'ConfinementTrack',Session = '1', ExperimentID = 15096) %>%
  mutate(PID = ifelse(is.na(PID), `Participant Private ID`, PID)) %>%
  select(Session, PID, Run, `Question Key`, `Response`, `UTC Timestamp`)

#verify number of ID after selection with criterion
countID <- ConfTrack %>%   #1006 PID
    group_by(PID) %>%
  summarise(n = n())
 
ConfTrack %>%             #1004 PID
  filter(`Question Key` %in% 'ConfStage' | `Question Key` %in% 'ConfStage-2') %>%
    group_by(PID) %>%
  summarise(n = n())




tracker <- ConfTrack %>%
  filter(`Question Key` %in% 'ConfStage' | `Question Key` %in% 'ConfStage-2') %>%
  mutate(Conftrack = Response) %>%
  select(PID, Run, Conftrack)

#number of occurence for each Conftracker response
tracker %>%
  group_by(Conftrack, Run) %>%
  summarise(n = n())




#count different participants that took part in the session 1 
Nback %>% 
  group_by(PID) %>%
  summarise(n = n())
 #417 participants



#merge Conftracker and Nback, keep only responses for run made during confinement.
Nback <- left_join(Nback, tracker, by = c("PID", "Run")) %>%
  filter(Conftrack == "pendant")

#375,000 --> 359,000

#verify number of participant after tracker
  Nback %>%
  count(PID) 
  #412 --> 383 participants
```






#Retrospective / prospective
```{r}
#add a column "block number" identifying each trial of session 1
#keep only first Run 1 for participants that did 2 or 3 Run1

Nback <- Nback %>%
  mutate(end = `Zone.Type` == "response_rating_scale_likert",
         block_nb = cumsum(end),
         block_nb = ifelse(end == T, block_nb - 1, block_nb)) %>%
  select(-end)

#Count tasks
Nback %>%
  count(block_nb) #4274

retrosp <- Nback %>%
  group_by(PID, Run, condition) %>%
  filter(!is.na(condition)) %>%
  summarise(block_nb = first(block_nb), UTC.Timestamp = first(UTC.Timestamp)) %>%
  group_by(PID) %>%
  dplyr::slice(which.min(UTC.Timestamp))

Nback <- Nback %>%
  mutate(retro.pro = ifelse(
    block_nb %in% retrosp$block_nb, "retrospective",  "prospective"))
  

Nback %>%
  group_by(block_nb) %>%
  summarise(retro.pro = first(retro.pro)) %>%
  count(retro.pro)
#378 first an thus retrospective task

```






#Deal with attempts
```{r}

##keyboard response Attempts
Table_Attempts <- Nback %>%  
  group_by(Attempt) %>%
  count() %>%
  filter(as.numeric(Attempt) <10)
paged_table(Table_Attempts)
# ~13 000 out of ~160 000    #8%

Nback <- Nback %>%            #removing all responses with more than one Attempt
  filter( Zone.Type != "response_keyboard" | Attempt %in% c("1", NA))
#~375000 obs --> 344200 obs


##Response text entry and likert Attempts

Nback %>% 
  filter(Zone.Type == "response_rating_scale_likert") %>%
  group_by(Attempt) %>%
  count()
#only one Attempts

Nback %>% 
  filter(Zone.Type == "response_text_entry") %>%
  group_by(Attempt) %>%
  count()
#19 responses with more than 1 Attempts

entry_attempt <- Nback %>% 
  filter(Zone.Type == "response_text_entry" & Attempt > 1) 
  
  Nback %>% 
    filter(Zone.Type == "response_text_entry") %>%
    filter(PID %in% entry_attempt$PID
           & nback %in% entry_attempt$nback 
           & randomblock %in% entry_attempt$randomblock )
#the responses for both attempts are identical --> keep the first one
  
  
  Nback <- Nback %>%            #removing all responses with more than one Attempt
  filter( Zone.Type != "response_text_entry" | Attempt %in% c("1", NA))
  
  

  #tester replicated


```

#Number of responses
```{r}
Nback %>%
  group_by(block_nb, .add = T) %>%
  filter(Response %in% c("Left", "Down")) %>%
  summarise(n= n(), duration = first(duration)) %>%
  group_by(duration) %>%
  group_by(n, .add = T) %>%
  summarise(nn = n())

number_resp = Nback %>%
   group_by(duration, ILI, nback) %>%
  group_by(block_nb, .add = T) %>%
  filter(Response %in% c("Left", "Down")) %>%
  summarise(n = n(), duration = first(duration))


number_resp %>%
  filter(!is.na(duration)) %>%
  ggplot(aes(n, group = duration, colour = duration)) +
  facet_grid(duration~ILI) +
           geom_histogram(position = "dodge", binwidth=1,
                   colour = "black" , fill="white") +
  labs(y = "count", x = "Number of Responses", title ="Number of responses (Down or Left) for 45s and 90s tasks") +
  theme(plot.title = element_text(face = "bold", "hjust" = 0.5)) 
  # scale_x_continuous(limits = c(0, 70), breaks = seq(from = 0, to = 70, by = 5))

#some task have 2 times or 3 times more responses than expected
```

```{r}

nbresp <- Nback %>%
  filter(Zone.Type == "response_keyboard") %>%
  select(block_nb, condition) %>%
    group_by(block_nb) %>%
summarise(n = n(),condition = first(condition))

blocktorm1 <- nbresp %>%   #1500 45
  filter(condition == 1) %>%
  filter(is.na(block_nb) | n > 31)

blocktorm2 <- nbresp %>%       #1500 90s
  filter(condition == 2) %>%
  filter(is.na(block_nb) | n> 60)

blocktorm3 <- nbresp %>%     #1800 45s
  filter(condition == 3) %>%
  filter(is.na(block_nb) | n > 26)

blocktorm4 <- nbresp %>%       #1800 90s
  filter(condition == 4) %>%
  filter(is.na(block_nb) | n> 51)

blocktorm <- bind_rows(blocktorm1, blocktorm2, blocktorm3, blocktorm4) #6 blocks


Nback <- Nback %>%
  filter(!(block_nb %in% blocktorm$block_nb))

blocknb <-Nback %>%
  group_by(block_nb) %>%
  summarise(n = n()) 
blocknb
#4221 trials


number_resp = Nback %>%
   group_by(duration, ILI, nback) %>%
  group_by(block_nb, .add = T) %>%
  filter(Response %in% c("Left", "Down")) %>%
  summarise(n = n(), duration = first(duration))

number_resp %>%
  filter(!is.na(duration)) %>%
  ggplot(aes(n, group = duration, colour = duration)) +
  facet_grid(duration~ILI) +
           geom_histogram(position = "dodge", binwidth=1,
                   colour = "black" , fill="white") +
  labs(y = "count", x = "Number of Responses", title ="Number of responses (Down or Left) for 45s and 90s tasks") +
  theme(plot.title = element_text(face = "bold", "hjust" = 0.5)) +
  scale_x_continuous(limits = c(0, 60), breaks = seq(from = 0, to = 60, by = 5))


```






##Filtering and formatting data
```{r}

# Remove excess tasks (for duration estimation and likert response columns)
first_trial <- Nback %>%   #3913 tasks
  filter(Zone.Type == "response_text_entry") %>%
  group_by(PID) %>%
  group_by(nback, .add =T) %>%
  group_by(Run, .add =T) %>%
  group_by(randomblock, .add =T) %>%
  dplyr::slice(which.min(UTC.Timestamp)) %>%
  select(block_nb)


trials_to_rm <- setdiff(blocknb$block_nb, first_trial$block_nb)  #295 observations

Nback <- Nback %>%
        filter(!(block_nb %in% trials_to_rm))  #342966 --> 318449 observations



#merge entry response (likert scale and duration estimation) with other responses
df1 <- Nback %>% 
  filter(Zone.Type == "response_keyboard") %>%
  select(-Zone.Type) 

df2 <-Nback %>% 
  filter(Zone.Type == "response_text_entry" | Zone.Type == "response_rating_scale_likert") %>% 
  select(-UTC.Timestamp, - Reaction.Time, - Attempt, -retro.pro, - ntarget, -notarget) %>% 
  mutate(Response = as.character(Response)) %>% 
  pivot_wider(values_from = Response, names_from = Zone.Type) 


Nback_all <- left_join(df1, df2, by = c("PID", "Session", "nback", "randomblock", "Run", "block_nb", "Conftrack")) %>%
  select(-Correct.y, - duration.y, -ILI.y, - condition.y) %>%
  filter(!is.na(response_text_entry)) %>%
  rename(duration = duration.x, 
         ILI = ILI.x, 
         Correct = Correct.x,
         condition = condition.x,
         response_arrow = Response,
         likert = response_rating_scale_likert) %>%
mutate(Run = as.factor(Run),
  likert = fct_relevel(likert, "Très lentement", "Lentement", "Normalement", "Rapidement", "Très rapidement"))


Nback_all %>% 
  group_by(PID) %>%
  summarise(n = n())
Nback_all %>% 
  group_by(block_nb) %>%
  summarise(n = n())

#370 participants + 3845 blocks  

```





##translating subjective duration estimates and add them to Nback
```{r}

outdir = "/home/user/Desktop/Documents/TimeSocialDistancing/data_exp_15096-16303_FR_processed"

##formatting and translating subjective duration estimates

#getting rid of spaces, punctuation, "::" and words that beginning by "m" (for minutes)
subj_duration = Nback %>% filter(Zone.Type == "response_text_entry") %>% 
  select(PID, Response, Run, randomblock, nback) %>% 
  mutate(Response = str_to_lower(as.character(Response)),
          Response = str_replace_all(Response, regex("m([a-z]{0,})"), ":"),
          Response = str_replace_all(Response, regex("[:punct:]"), ":"),
          Response = str_replace_all(Response, regex("[:space:]"), ""),
          Response = str_replace_all(Response, "::", ":"))

subj_duration1 <- subj_duration %>% 
  mutate(translated = strtoi(
    as.difftime(Response, format = "%M:%S", units = "sec")))  #recognize duration with format (mm:ss)

subj_duration2 <- subj_duration1 %>% 
  filter(is.na(translated)) %>%   #among duration not yet translated
  mutate(translated = ifelse(
    str_detect(Response, regex("(\\d{1,2})s([a-z]{0,})")),     #if two digit only, recognize them as (ss)
     strtoi(as.difftime(Response, format = c("%S"), units = "sec")),
    NA)) 
subj_duration3 <- subj_duration2 %>% 
  filter(is.na(translated)) %>%   #among duration not yet translated
  mutate( translated = ifelse(
    str_detect(Response, regex("\\d{4}")),    #if series of 4 digits, recognize them as (mmss)
     strtoi(as.difftime(Response, format = c("%M%S"), units = "sec")),
    NA)) 
subj_duration4 = subj_duration3 %>% 
  filter(is.na(translated)) %>%  #among duration not yet translated
  mutate( translated = ifelse(          
   parse_number(Response) < 3,                #if only one digit <9, recognize them as (m)
     strtoi(as.difftime(Response, format = c("%M"), units = "sec")),
    NA))
subj_duration5 = subj_duration4 %>% 
  filter(is.na(translated)) %>%  #among duration not yet translated
  mutate(translated = parse_number(Response)) #extract only the number from the string

subj_duration6 = subj_duration5 %>% 
  filter(is.na(translated)) %>%  #among duration not yet translated
  mutate(translated = strtoi(
    as.difftime(Response, format = "%S:00", units = "sec")))  #recognize duration with format (ss:mm)

#merge each dataframe with their translated values
subj_duration = full_join(subj_duration1, subj_duration2, copy = F) %>% filter(!is.na(translated))
subj_duration = full_join(subj_duration, subj_duration3, copy = F) %>% filter(!is.na(translated))
subj_duration = full_join(subj_duration, subj_duration4, copy = F) %>% filter(!is.na(translated))
subj_duration = full_join(subj_duration, subj_duration5, copy = F) %>% 
  mutate(translated = ifelse(translated > 500, translated/60, translated),
         translated = ifelse(translated < 6, translated*60, translated))  

#get the duration estimation that ave strange formats and translate them manually 
no_translated = subj_duration  %>% 
  filter(is.na(translated))     #26 no translated 
# %>% 
#  write_csv(file.path(outdir,'no_translated.csv')) 


#merge subj_duration with Nback ==> add translated estimates
Nback_all <- left_join(Nback_all, subj_duration, by = c("PID", "Run", "nback", "randomblock")) %>%
  filter(!is.na(translated))   

Nback_all <- Nback_all %>% select(PID, nback, Run, block_nb, ILI, duration, condition, likert, translated, Reaction.Time, response_arrow, Correct, ntarget, notarget, UTC.Timestamp, retro.pro) %>%
  write_csv(file.path(outdir,'S1_nback.csv'))

paged_table(Nback_all)  #133232

#Count overall number of trials (8 trials per Run per Participants ) #3845 --> 3812 (25) responses not translated)

Nback_blocks <- Nback_all %>%
  group_by(PID) %>%
  group_by(nback, .add = T) %>%
  group_by(Run, .add = T) %>%
  group_by(duration, ILI, .add = T) %>%
  summarise(likert = first(likert), 
            translated = first(translated),
            block_nb = first(block_nb)) %>%
  ungroup()

paged_table(Nback_blocks)

```








```{r}
##Extracting 1-Back

# datadir = file.path(params$rootdir,paste0('data_exp_', paste(params$ExperimentID,collapse='-'), '_', ExperimentName[1]))
# outdir = paste(datadir,'processed',sep='_')
# dir.create(outdir,showWarnings = F)
# ExperimentID <- params$ExperimentID
# 
# 
# datafiles <- list.files(datadir,'S1_1back_r.*.csv',full.names = T)
# tmpdir <- file.path(params$rootdir,'.tmp')
# unlink(tmpdir,recursive=T)
# if (is_empty(datafiles)){
#   print('No 1back data')
#   knitr::knit_exit()
# }
# 
# orig1back <- T_read(datafiles) %>%
#   mutate(Run = as.factor(str_replace(File,'S._1back_r(.).csv','\\1'))) 
# 
# 
# ##Extracting 3-Back
# 
# 
# datafiles <- list.files(datadir,'S1_3back_r.*.csv',full.names = T)
# tmpdir <- file.path(params$rootdir,'.tmp')
# unlink(tmpdir,recursive=T)
# if (is_empty(datafiles)){
#   print('No 3back data')
#   knitr::knit_exit()
# }
# 
# orig3back <- T_read(datafiles) %>%
#   mutate(Run = as.factor(str_replace(File,'S._3back_r(.).csv','\\1'))) 
```

#Select and modify columns of interest and merge 1-back and 3-back
```{r}
# Orig1back = orig1back %>%
#   filter(str_detect(display, "block1back")) %>%
#   select(Correct, ILI,`Reaction Time`,PID,`Zone Type`, duration, Response, Run, randomblock, Attempt,  `UTC Timestamp`) %>%
#   mutate(nback = "1back",
#          `UTC Timestamp`= as.character(`UTC Timestamp`)) %>%
#   rename(PID = PID,
#          Zone.Type = `Zone Type`,
#          UTC.Timestamp = `UTC Timestamp`,
#          Reaction.Time = `Reaction Time`)
# 
# Orig3back = orig3back %>%
#   filter(str_detect(display, "block3back")) %>%
#   select(Correct, ILI,`Reaction Time`,PID,`Zone Type`, duration, Response, Run, randomblock, Attempt,  `UTC Timestamp`) %>%
#   mutate(nback = "3back",
#          `UTC Timestamp`= as.character(`UTC Timestamp`)) %>%
#   rename(PID = PID,
#          Zone.Type = `Zone Type`,
#          UTC.Timestamp = `UTC Timestamp`,
#          Reaction.Time = `Reaction Time`)
# 
# OrigNback <- bind_rows(Orig1back, Orig3back) %>%
#   mutate(ILI = as.factor(ifelse(ILI  == 1500, "1500ms", "1800ms")),
#          duration = as.factor(duration),
#          timestamp = as.numeric(UTC.Timestamp),
# condition = ifelse(duration == "45s" & nback == "1back" & ILI == "1500ms", 1, 0),
#          condition = ifelse(duration == "90s" & nback == "1back" & ILI == "1500ms", 2, condition),
#          condition = ifelse(duration == "45s" & nback == "1back" & ILI == "1800ms", 3, condition),
#          condition = ifelse(duration == "90s" & nback == "1back" & ILI == "1800ms", 4, condition),
#          condition = ifelse(duration == "45s" & nback == "3back" & ILI == "1500ms", 5, condition),
#          condition = ifelse(duration == "90s" & nback == "3back" & ILI == "1500ms", 6, condition),
#          condition = ifelse(duration == "45s" & nback == "3back" & ILI == "1800ms", 7, condition),
#          condition = ifelse(duration == "90s" & nback == "3back" & ILI == "1800ms", 8, condition))
```





